# -*- coding: utf-8 -*-
"""CustomerChurnANN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yz8idSUx0dcQEQxH7-Ppg-X8lulovVn9
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
from matplotlib import pyplot as plt
import numpy as np
import tensorflow as tf
from tensorflow import keras
from sklearn.metrics import confusion_matrix , classification_report
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

# %matplotlib inline
import warnings
warnings.filterwarnings('ignore')
df = pd.read_csv("customer_churn.csv")
df.sample(5)
df.Churn.value_counts()
517400/df.shape[0]
df.drop(['customerID','Partner','PhoneService','MultipleLines','OnlineSecurity','OnlineBackup', 'DeviceProtection','TechSupport','StreamingTV','StreamingMovies','PaperlessBilling','MonthlyCharges','TotalCharges','InternetService'],axis='columns',inplace=True)
print(f"{df}")
df.dtypes


df[df.Churn=='No']
tenure_churn_no = df[df.Churn=='No'].tenure
tenure_churn_yes = df[df.Churn=='Yes'].tenure


def print_unique_col_values(df):
       for column in df:
            if df[column].dtypes=='object':
                print(f'{column}: {df[column].unique()}')
print_unique_col_values(df)

print_unique_col_values(df)
yes_no_columns = ['Dependents','Churn']
for col in yes_no_columns:
    df[col].replace({'Yes': 1,'No': 0},inplace=True)
for col in df:
    print(f'{col}: {df[col].unique()}')
df['gender'].replace({'Female':1,'Male':0},inplace=True)
df.gender.unique()
# Define mapping dictionaries for categorical variables

contract_mapping = {'Month-to-month': 0, 'One year': 1, 'Two year': 2}
payment_method_mapping = {'Electronic check': 0, 'Mailed check': 1, 'Bank transfer (automatic)': 2, 'Credit card (automatic)': 3}
# Apply mapping to the DataFrame
df['Contract'] = df['Contract'].map(contract_mapping)
df['PaymentMethod'] = df['PaymentMethod'].map(payment_method_mapping)
df.columns
df.sample(5)
df.dtypes
cols_to_scale = ['tenure','Contract','PaymentMethod']

scaler = MinMaxScaler()
df[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])
for col in df:
    print(f'{col}: {df[col].unique()}')
# X = df2.drop('Churn',axis='columns')
# y = testLabels = df2.Churn.astype(np.float32)
# Method 1: Undersampling

count_class_0, count_class_1 = df.Churn.value_counts()

# Divide by class
df_class_0 = df[df['Churn'] == 0]
df_class_1 = df[df['Churn'] == 1]
# Undersample 0-class and concat the DataFrames of both class
# df_class_0_under = df_class_0.sample(count_class_1)

# df_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)

# print('Random under-sampling:')
# print(df_test_under.Churn.value_counts())

# X = df_test_under.drop('Churn',axis='columns')
# y = df_test_under['Churn']

# Oversample 1-class and concat the DataFrames of both class
df_class_1_over = df_class_1.sample(count_class_0,replace=True)
df_test_over = pd.concat([df_class_1_over, df_class_0], axis=0)
print('Random over-sampling:')
print(df_test_over.Churn.value_counts())
X = df_test_over.drop('Churn',axis='columns')
y = df_test_over['Churn']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)
y_train.value_counts()
y.value_counts()
5163/1869
print(f"Y Test values:\n{y_test.value_counts()}")
X_train.shape
X_test.shape
X_train[:10]

print(f"Input shape for ANN training data:{len(X_train.columns)}")
X_train
X_test = np.asarray(X_test).astype(np.float32)
y_test = np.asarray(y_test).astype(np.float32)
print(f"First record of input data:{X_test[0]}")

# Step 3: Build the Neural Network
model = keras.Sequential([
    keras.layers.Dense(64, input_shape=(len(X_train.columns),), activation='relu'),
    keras.layers.Dense(64, activation='relu'),
    keras.layers.Dense(1, activation='sigmoid')
])

# Step 4: Compile the Model
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Step 5: Train the Model
X_train = np.asarray(X_train).astype(np.float32)
y_train = np.asarray(y_train).astype(np.float32)
history = model.fit(X_train, y_train, epochs=80, batch_size=32, validation_split=0.2)

# Step 6: Evaluate the Model
test_loss, test_acc = model.evaluate(X_test, y_test)
print('Test accuracy:', test_acc)

# Generate predictions
y_pred = model.predict(X_test)
y_pred_classes = (y_pred > 0.5).astype("int32")  # Ensure prediction is integers (0 or 1)
print(f"{y_pred_classes}")

# Classification report and confusion matrix
print(classification_report(y_test, y_pred_classes))
print(confusion_matrix(y_test, y_pred_classes))
# Save model
model.save('customer.h5')